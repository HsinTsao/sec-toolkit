"""
åŒ LLM æ¶æ„ Agent

å®ç°é«˜æ•ˆçš„ Token æ¶ˆè€—ä¼˜åŒ–æ¶æ„ï¼š
    User Input â†’ Intent LLM (~200 tokens) â†’ Router â†’ Tool â†’ Summary LLM (~200 tokens)

ç›¸æ¯”ä¼ ç»Ÿ Tool Calling æ¶æ„ï¼ŒToken æ¶ˆè€—é™ä½ 60-70%ã€‚

ä½¿ç”¨ç¤ºä¾‹:
    agent = DualLLMAgent(llm_config)
    result = await agent.process("æŠŠ hello world è½¬æˆ base64")
    # result.content = "Base64 ç¼–ç ç»“æœ: aGVsbG8gd29ybGQ="
    # result.tokens_used â‰ˆ 400 (vs ä¼ ç»Ÿæ¶æ„ ~1500)
"""

import json
import asyncio
import httpx
import logging
from typing import Any, Dict, Optional, AsyncGenerator, List
from pydantic import BaseModel, Field
from enum import Enum

from .intent import (
    IntentCategory,
    ParsedIntent,
    try_rule_match,
    parse_llm_intent_response,
    get_tool_display_name,
    get_intent_system_prompt,  # åŠ¨æ€è·å– Promptï¼ˆå¤‡ç”¨ï¼‰
    INTENT_USER_TEMPLATE,
    SUMMARY_SYSTEM_PROMPT,
    SUMMARY_USER_TEMPLATE,
    TOOL_CATEGORY_MAP,
)
from .executor import tool_executor
from .registry import tool_registry
from .base import ToolResult

logger = logging.getLogger(__name__)


class AgentMode(str, Enum):
    """Agent è¿è¡Œæ¨¡å¼"""
    FAST = "fast"        # åŒ LLM æ¨¡å¼ï¼ˆçœ tokenï¼‰
    FULL = "full"        # å®Œæ•´ Tool Calling æ¨¡å¼ï¼ˆå¼ºèƒ½åŠ›ï¼‰
    AUTO = "auto"        # è‡ªåŠ¨é€‰æ‹©


class DualLLMResult(BaseModel):
    """åŒ LLM Agent æ‰§è¡Œç»“æœ"""
    success: bool = Field(..., description="æ˜¯å¦æˆåŠŸ")
    content: str = Field(..., description="æœ€ç»ˆå›å¤å†…å®¹")
    intent: Optional[ParsedIntent] = Field(None, description="è¯†åˆ«çš„æ„å›¾")
    tool_result: Optional[Dict[str, Any]] = Field(None, description="å·¥å…·æ‰§è¡Œç»“æœ")
    mode_used: AgentMode = Field(default=AgentMode.FAST, description="ä½¿ç”¨çš„æ¨¡å¼")
    tokens_estimated: int = Field(default=0, description="ä¼°ç®— token æ¶ˆè€—")
    rule_matched: bool = Field(default=False, description="æ˜¯å¦è§„åˆ™åŒ¹é…ï¼ˆ0 tokenï¼‰")


class LLMConfig(BaseModel):
    """LLM é…ç½®"""
    base_url: str
    api_key: str
    model: str
    # å¯é€‰ï¼šç‹¬ç«‹çš„ Intent/Summary æ¨¡å‹ï¼ˆæ›´çœ tokenï¼‰
    intent_model: Optional[str] = None
    summary_model: Optional[str] = None


class DualLLMAgent:
    """
    åŒ LLM æ¶æ„ Agent
    
    å·¥ä½œæµç¨‹:
    1. è§„åˆ™ä¼˜å…ˆåŒ¹é…ï¼ˆ0 tokenï¼‰
    2. å¦‚æœè§„åˆ™åŒ¹é…å¤±è´¥ï¼Œè°ƒç”¨ Intent LLM (~200 tokens)
    3. Deterministic Router æ ¹æ®æ„å›¾è°ƒç”¨å·¥å…·ï¼ˆ0 tokenï¼‰
    4. ç®€å•ç»“æœç›´æ¥è¿”å›ï¼ˆ0 tokenï¼‰ï¼Œå¤æ‚ç»“æœè°ƒç”¨ Summary LLM (~200 tokens)
    
    æ€»æ¶ˆè€—: 0-400 tokensï¼ˆä¼ ç»Ÿæ¶æ„: 1000-2000 tokensï¼‰
    """
    
    def __init__(self, config: LLMConfig, use_shared_client: bool = False):
        self.config = config
        self._client: Optional[httpx.AsyncClient] = None
        self._use_shared_client = use_shared_client
        self._owns_client = False  # æ ‡è®°æ˜¯å¦æ‹¥æœ‰å®¢æˆ·ç«¯ï¼ˆéœ€è¦è‡ªå·±å…³é—­ï¼‰
    
    @property
    def client(self) -> httpx.AsyncClient:
        """è·å– HTTP å®¢æˆ·ç«¯ï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼Œç”¨äºå…¼å®¹ï¼‰"""
        if self._client is None:
            self._client = httpx.AsyncClient(timeout=60.0)
            self._owns_client = True
        return self._client
    
    async def get_client(self) -> httpx.AsyncClient:
        """è·å– HTTP å®¢æˆ·ç«¯ï¼ˆå¼‚æ­¥ç‰ˆæœ¬ï¼Œæ”¯æŒå…±äº«å®¢æˆ·ç«¯ï¼‰"""
        if self._use_shared_client:
            return await get_shared_client(self.config.base_url)
        if self._client is None:
            self._client = httpx.AsyncClient(timeout=60.0)
            self._owns_client = True
        return self._client
    
    async def close(self):
        """å…³é—­å®¢æˆ·ç«¯ï¼ˆä»…å…³é—­è‡ªå·±åˆ›å»ºçš„å®¢æˆ·ç«¯ï¼Œä¸å…³é—­å…±äº«å®¢æˆ·ç«¯ï¼‰"""
        if self._client and self._owns_client:
            await self._client.aclose()
            self._client = None
            self._owns_client = False
    
    async def process(
        self,
        user_input: str,
        mode: AgentMode = AgentMode.AUTO,
        skip_summary: bool = False,
        user_context: Optional[Dict[str, Any]] = None,
    ) -> DualLLMResult:
        """
        å¤„ç†ç”¨æˆ·è¾“å…¥
        
        Args:
            user_input: ç”¨æˆ·è¾“å…¥æ–‡æœ¬
            mode: è¿è¡Œæ¨¡å¼
            skip_summary: æ˜¯å¦è·³è¿‡ Summary LLMï¼ˆç›´æ¥è¿”å›åŸå§‹ç»“æœï¼‰
            user_context: ç”¨æˆ·ä¸Šä¸‹æ–‡ï¼ˆä½ç½®ã€æ—¶åŒºç­‰ï¼‰
            
        Returns:
            DualLLMResult: æ‰§è¡Œç»“æœ
        """
        user_context = user_context or {}
        tokens_used = 0
        rule_matched = False
        
        # ========== é˜¶æ®µ 1: æ„å›¾è¯†åˆ« ==========
        
        # 1.1 å°è¯•è§„åˆ™åŒ¹é…ï¼ˆ0 tokenï¼‰
        intent = try_rule_match(user_input)
        
        if intent:
            rule_matched = True
            logger.info(f"è§„åˆ™åŒ¹é…æˆåŠŸ: {intent.tool}")
        else:
            # 1.2 è°ƒç”¨ Intent LLM
            if mode == AgentMode.FULL:
                # å®Œæ•´æ¨¡å¼ï¼Œç›´æ¥ fallback åˆ°èŠå¤©
                return DualLLMResult(
                    success=True,
                    content="",  # ç”±ä¸Šå±‚å¤„ç†
                    intent=ParsedIntent(category=IntentCategory.CHAT, raw_input=user_input),
                    mode_used=AgentMode.FULL,
                    tokens_estimated=0,
                )
            
            intent = await self._call_intent_llm(user_input)
            tokens_used += 250  # ä¼°ç®— Intent LLM æ¶ˆè€—
            logger.info(f"Intent LLM è¯†åˆ«: category={intent.category}, tool={intent.tool}")
        
        # ========== é˜¶æ®µ 2: è·¯ç”±å†³ç­– ==========
        
        # å¦‚æœæ˜¯èŠå¤©æˆ–åˆ†æç±»ï¼Œå§‹ç»ˆ fallback åˆ°å®Œæ•´ LLM
        # æ³¨æ„ï¼šIntent LLM çš„ç›®çš„æ˜¯è¯†åˆ«æ„å›¾ï¼Œä¸æ˜¯ç”Ÿæˆå®Œæ•´å›å¤
        # å®ƒçš„ max_tokens è¾ƒå°ï¼Œå›å¤ä¼šè¢«æˆªæ–­ï¼Œæ‰€ä»¥ä¸åº”è¯¥ç›´æ¥ä½¿ç”¨
        if intent.category in (IntentCategory.CHAT, IntentCategory.ANALYZE):
            logger.info(f"CHAT/ANALYZE ç±»å‹ï¼Œéœ€è¦ fallback åˆ°å®Œæ•´ LLM")
            return DualLLMResult(
                success=True,
                content="",  # æ ‡è®°éœ€è¦ fallback
                intent=intent,
                mode_used=AgentMode.FULL,
                tokens_estimated=tokens_used,
                rule_matched=rule_matched,
            )
        
        # ========== é˜¶æ®µ 3: å·¥å…·æ‰§è¡Œ (0 token) ==========
        
        if not intent.tool:
            return DualLLMResult(
                success=False,
                content="æ— æ³•è¯†åˆ«è¦æ‰§è¡Œçš„å·¥å…·",
                intent=intent,
                mode_used=AgentMode.FAST,
                tokens_estimated=tokens_used,
                rule_matched=rule_matched,
            )
        
        # æ³¨å…¥ç”¨æˆ·ä¸Šä¸‹æ–‡åˆ°å·¥å…·å‚æ•°
        tool_params = dict(intent.params)
        if intent.tool == "weather" and user_context.get("location"):
            # å¦‚æœç”¨æˆ·æ²¡æœ‰æŒ‡å®šä½ç½®ï¼Œä½¿ç”¨ä¸Šä¸‹æ–‡ä¸­çš„ä½ç½®
            if not tool_params.get("location"):
                tool_params["location"] = user_context["location"]
                logger.info(f"ä½¿ç”¨ç”¨æˆ·ä¸Šä¸‹æ–‡ä½ç½®: {user_context['location']}")
        
        tool_result = await tool_executor.execute(
            intent.tool,
            tool_params,
            require_confirmation=False,
        )
        
        # ========== é˜¶æ®µ 4: ç»“æœå¤„ç† ==========
        
        if skip_summary:
            # ç›´æ¥è¿”å›åŸå§‹ç»“æœ
            return DualLLMResult(
                success=tool_result.success,
                content=self._format_raw_result(intent, tool_result),
                intent=intent,
                tool_result=tool_result.model_dump(),
                mode_used=AgentMode.FAST,
                tokens_estimated=tokens_used,
                rule_matched=rule_matched,
            )
        
        # ç®€å•ç»“æœç›´æ¥æ ¼å¼åŒ–è¿”å›ï¼ˆ0 tokenï¼‰
        if tool_result.success and self._is_simple_result(tool_result.data):
            content = self._format_simple_result(intent, tool_result)
            return DualLLMResult(
                success=True,
                content=content,
                intent=intent,
                tool_result=tool_result.model_dump(),
                mode_used=AgentMode.FAST,
                tokens_estimated=tokens_used,
                rule_matched=rule_matched,
            )
        
        # å¤æ‚ç»“æœè°ƒç”¨ Summary LLM
        content = await self._call_summary_llm(intent, tool_result)
        tokens_used += 250  # ä¼°ç®— Summary LLM æ¶ˆè€—
        
        return DualLLMResult(
            success=tool_result.success,
            content=content,
            intent=intent,
            tool_result=tool_result.model_dump(),
            mode_used=AgentMode.FAST,
            tokens_estimated=tokens_used,
            rule_matched=rule_matched,
        )
    
    async def process_stream(
        self,
        user_input: str,
        mode: AgentMode = AgentMode.AUTO,
    ) -> AsyncGenerator[Dict[str, Any], None]:
        """
        æµå¼å¤„ç†ç”¨æˆ·è¾“å…¥
        
        Yields:
            é˜¶æ®µæ€§ç»“æœï¼ŒåŒ…å«:
            - {"stage": "intent", "data": {...}}
            - {"stage": "tool", "data": {...}}
            - {"stage": "content", "data": "..."}
            - {"stage": "done", "data": {...}}
        """
        tokens_used = 0
        rule_matched = False
        
        # é˜¶æ®µ 1: æ„å›¾è¯†åˆ«
        intent = try_rule_match(user_input)
        
        if intent:
            rule_matched = True
            yield {"stage": "intent", "data": {
                "category": intent.category.value,
                "tool": intent.tool,
                "rule_matched": True,
            }}
        else:
            if mode == AgentMode.FULL:
                yield {"stage": "fallback", "data": {"reason": "full_mode"}}
                return
            
            yield {"stage": "intent", "data": {"status": "calling_llm"}}
            intent = await self._call_intent_llm(user_input)
            tokens_used += 250
            
            yield {"stage": "intent", "data": {
                "category": intent.category.value,
                "tool": intent.tool,
                "confidence": intent.confidence,
                "rule_matched": False,
            }}
        
        # éœ€è¦ fallback åˆ°å®Œæ•´ LLM
        if intent.category in (IntentCategory.CHAT, IntentCategory.ANALYZE):
            yield {"stage": "fallback", "data": {
                "reason": intent.category.value,
                "tokens_used": tokens_used,
            }}
            return
        
        if not intent.tool:
            yield {"stage": "error", "data": {"message": "æ— æ³•è¯†åˆ«å·¥å…·"}}
            return
        
        # é˜¶æ®µ 2: å·¥å…·æ‰§è¡Œ
        yield {"stage": "tool", "data": {
            "name": intent.tool,
            "display_name": get_tool_display_name(intent.tool),
            "params": intent.params,
            "status": "executing",
        }}
        
        tool_result = await tool_executor.execute(
            intent.tool,
            intent.params,
            require_confirmation=False,
        )
        
        yield {"stage": "tool", "data": {
            "name": intent.tool,
            "status": "completed",
            "success": tool_result.success,
            "result": tool_result.model_dump(),
        }}
        
        # é˜¶æ®µ 3: ç»“æœè¾“å‡º
        if tool_result.success and self._is_simple_result(tool_result.data):
            content = self._format_simple_result(intent, tool_result)
            yield {"stage": "content", "data": content}
        else:
            yield {"stage": "summary", "data": {"status": "calling_llm"}}
            content = await self._call_summary_llm(intent, tool_result)
            tokens_used += 250
            yield {"stage": "content", "data": content}
        
        # å®Œæˆ
        yield {"stage": "done", "data": {
            "tokens_estimated": tokens_used,
            "rule_matched": rule_matched,
            "mode": AgentMode.FAST.value,
        }}
    
    async def _call_intent_llm(self, user_input: str) -> ParsedIntent:
        """è°ƒç”¨ Intent LLM è¯†åˆ«æ„å›¾ï¼ˆä½¿ç”¨ Function Callingï¼‰"""
        import time
        start_time = time.time()
        model = self.config.intent_model or self.config.model
        
        logger.debug(f"ğŸ§  [IntentLLM] å¼€å§‹è°ƒç”¨ Function Calling: model={model}, input={user_input[:50]}...")
        
        # è·å– OpenAI æ ¼å¼çš„å·¥å…·åˆ—è¡¨
        tools = tool_registry.get_openai_tools()
        
        messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ã€‚æ ¹æ®ç”¨æˆ·çš„è¯·æ±‚ï¼Œé€‰æ‹©åˆé€‚çš„å·¥å…·æ¥å®Œæˆä»»åŠ¡ã€‚å¦‚æœä¸éœ€è¦å·¥å…·ï¼Œç›´æ¥å›å¤ç”¨æˆ·ã€‚"},
            {"role": "user", "content": user_input},
        ]
        
        try:
            request_body = {
                "model": model,
                "messages": messages,
                "max_tokens": 500,
                "temperature": 0.1,
            }
            
            # å¦‚æœæœ‰å·¥å…·ï¼Œæ·»åŠ  tools å‚æ•°
            if tools:
                request_body["tools"] = tools
                request_body["tool_choice"] = "auto"  # è®©æ¨¡å‹è‡ªåŠ¨å†³å®šæ˜¯å¦è°ƒç”¨å·¥å…·
            
            client = await self.get_client()
            response = await client.post(
                f"{self.config.base_url}/chat/completions",
                headers={
                    "Content-Type": "application/json",
                    "Authorization": f"Bearer {self.config.api_key}",
                },
                json=request_body,
            )
            
            elapsed = (time.time() - start_time) * 1000
            
            if response.status_code != 200:
                logger.error(f"ğŸ§  [IntentLLM] è°ƒç”¨å¤±è´¥: status={response.status_code}, body={response.text[:200]}, è€—æ—¶={elapsed:.0f}ms")
                return ParsedIntent(category=IntentCategory.CHAT, raw_input=user_input)
            
            result = response.json()
            message = result["choices"][0]["message"]
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ tool_calls
            tool_calls = message.get("tool_calls", [])
            
            if tool_calls:
                # æ¨¡å‹é€‰æ‹©äº†å·¥å…·
                tool_call = tool_calls[0]  # å–ç¬¬ä¸€ä¸ªå·¥å…·è°ƒç”¨
                tool_name = tool_call["function"]["name"]
                tool_args_str = tool_call["function"]["arguments"]
                
                try:
                    tool_params = json.loads(tool_args_str)
                except json.JSONDecodeError:
                    tool_params = {}
                
                # ä»å·¥å…·åç§°æ¨æ–­åˆ†ç±»
                category = TOOL_CATEGORY_MAP.get(tool_name, IntentCategory.CHAT)
                
                logger.info(f"ğŸ§  [IntentLLM] Function Calling: tool={tool_name}, params={tool_params}, è€—æ—¶={elapsed:.0f}ms")
                
                return ParsedIntent(
                    category=category,
                    tool=tool_name,
                    params=tool_params,
                    confidence=0.95,  # Function Calling ç½®ä¿¡åº¦æ›´é«˜
                    raw_input=user_input,
                )
            else:
                # æ¨¡å‹æ²¡æœ‰é€‰æ‹©å·¥å…·ï¼Œè§†ä¸ºæ™®é€šèŠå¤©
                content = message.get("content", "")
                logger.info(f"ğŸ§  [IntentLLM] æ— å·¥å…·è°ƒç”¨ï¼Œfallback åˆ° CHAT: {content[:100]}, è€—æ—¶={elapsed:.0f}ms")
                
                return ParsedIntent(
                    category=IntentCategory.CHAT,
                    tool=None,
                    params={},
                    confidence=0.8,
                    raw_input=user_input,
                    direct_response=content if content else None,  # ä¿å­˜æ¨¡å‹çš„ç›´æ¥å›å¤
                )
            
        except Exception as e:
            elapsed = (time.time() - start_time) * 1000
            logger.error(f"ğŸ§  [IntentLLM] è°ƒç”¨å¼‚å¸¸: {e}, è€—æ—¶={elapsed:.0f}ms", exc_info=True)
            return ParsedIntent(category=IntentCategory.CHAT, raw_input=user_input)
    
    async def _call_summary_llm(self, intent: ParsedIntent, tool_result: ToolResult) -> str:
        """è°ƒç”¨ Summary LLM æ€»ç»“ç»“æœ"""
        import time
        start_time = time.time()
        model = self.config.summary_model or self.config.model
        
        logger.debug(f"ğŸ“ [SummaryLLM] å¼€å§‹è°ƒç”¨: model={model}, tool={intent.tool}")
        
        # æ ¼å¼åŒ–ç»“æœ
        if tool_result.success:
            result_text = json.dumps(tool_result.data, ensure_ascii=False, indent=2)
            if len(result_text) > 1000:
                result_text = result_text[:1000] + "\n...(ç»“æœå·²æˆªæ–­)"
        else:
            result_text = f"é”™è¯¯: {tool_result.error}"
        
        messages = [
            {"role": "system", "content": SUMMARY_SYSTEM_PROMPT},
            {"role": "user", "content": SUMMARY_USER_TEMPLATE.format(
                tool_name=get_tool_display_name(intent.tool or ""),
                input_text=json.dumps(intent.params, ensure_ascii=False),
                result=result_text,
            )},
        ]
        
        try:
            client = await self.get_client()
            response = await client.post(
                f"{self.config.base_url}/chat/completions",
                headers={
                    "Content-Type": "application/json",
                    "Authorization": f"Bearer {self.config.api_key}",
                },
                json={
                    "model": model,
                    "messages": messages,
                    "max_tokens": 300,
                    "temperature": 0.3,
                },
            )
            
            elapsed = (time.time() - start_time) * 1000
            
            if response.status_code != 200:
                logger.error(f"ğŸ“ [SummaryLLM] è°ƒç”¨å¤±è´¥: status={response.status_code}, è€—æ—¶={elapsed:.0f}ms")
                return self._format_raw_result(intent, tool_result)
            
            result = response.json()
            content = result["choices"][0]["message"]["content"]
            logger.info(f"ğŸ“ [SummaryLLM] æ€»ç»“å®Œæˆ: è€—æ—¶={elapsed:.0f}ms, é•¿åº¦={len(content)}")
            
            return content
            
        except Exception as e:
            elapsed = (time.time() - start_time) * 1000
            logger.error(f"ğŸ“ [SummaryLLM] è°ƒç”¨å¼‚å¸¸: {e}, è€—æ—¶={elapsed:.0f}ms", exc_info=True)
            return self._format_raw_result(intent, tool_result)
    
    def _is_simple_result(self, data: Any) -> bool:
        """åˆ¤æ–­æ˜¯å¦æ˜¯ç®€å•ç»“æœï¼ˆä¸éœ€è¦ LLM æ€»ç»“ï¼‰"""
        if data is None:
            return True
        if isinstance(data, str):
            return len(data) < 500
        if isinstance(data, (int, float, bool)):
            return True
        if isinstance(data, dict):
            # ç®€å•çš„é”®å€¼å¯¹
            return len(data) <= 3 and all(
                isinstance(v, (str, int, float, bool)) and 
                (not isinstance(v, str) or len(v) < 200)
                for v in data.values()
            )
        return False
    
    def _format_simple_result(self, intent: ParsedIntent, tool_result: ToolResult) -> str:
        """æ ¼å¼åŒ–ç®€å•ç»“æœï¼ˆ0 tokenï¼‰"""
        tool_name = get_tool_display_name(intent.tool or "")
        
        if not tool_result.success:
            return f"âŒ {tool_name} æ‰§è¡Œå¤±è´¥: {tool_result.error}"
        
        data = tool_result.data
        
        # å­—ç¬¦ä¸²ç»“æœ
        if isinstance(data, str):
            return f"âœ… **{tool_name}** ç»“æœ:\n```\n{data}\n```"
        
        # å­—å…¸ç»“æœ
        if isinstance(data, dict):
            if len(data) == 1:
                key, value = list(data.items())[0]
                return f"âœ… **{tool_name}** ç»“æœ:\n```\n{value}\n```"
            else:
                lines = [f"âœ… **{tool_name}** ç»“æœ:"]
                for key, value in data.items():
                    lines.append(f"- **{key}**: `{value}`")
                return "\n".join(lines)
        
        # å…¶ä»–ç±»å‹
        return f"âœ… **{tool_name}** ç»“æœ:\n```\n{data}\n```"
    
    def _format_raw_result(self, intent: ParsedIntent, tool_result: ToolResult) -> str:
        """æ ¼å¼åŒ–åŸå§‹ç»“æœï¼ˆfallbackï¼‰"""
        tool_name = get_tool_display_name(intent.tool or "")
        
        if not tool_result.success:
            return f"âŒ {tool_name} æ‰§è¡Œå¤±è´¥: {tool_result.error}"
        
        data = tool_result.data
        if isinstance(data, str):
            return f"âœ… {tool_name} ç»“æœ:\n```\n{data}\n```"
        
        return f"âœ… {tool_name} ç»“æœ:\n```json\n{json.dumps(data, ensure_ascii=False, indent=2)}\n```"


# ==================== å…±äº« HTTP å®¢æˆ·ç«¯æ±  ====================

import weakref
from typing import Dict

# å…¨å±€å…±äº«çš„ HTTP å®¢æˆ·ç«¯ï¼ˆæŒ‰ base_url åˆ†ç»„ï¼Œé¿å…é‡å¤åˆ›å»ºï¼‰
_shared_clients: Dict[str, httpx.AsyncClient] = {}
_client_lock = asyncio.Lock()


async def get_shared_client(base_url: str) -> httpx.AsyncClient:
    """è·å–å…±äº«çš„ HTTP å®¢æˆ·ç«¯ï¼ˆé¿å…æ¯æ¬¡è¯·æ±‚éƒ½åˆ›å»ºæ–°å®¢æˆ·ç«¯ï¼‰"""
    async with _client_lock:
        if base_url not in _shared_clients or _shared_clients[base_url].is_closed:
            _shared_clients[base_url] = httpx.AsyncClient(
                timeout=60.0,
                limits=httpx.Limits(max_keepalive_connections=10, max_connections=50),
            )
            logger.info(f"åˆ›å»ºå…±äº« HTTP å®¢æˆ·ç«¯: {base_url}")
        return _shared_clients[base_url]


async def cleanup_shared_clients():
    """æ¸…ç†æ‰€æœ‰å…±äº«å®¢æˆ·ç«¯ï¼ˆåº”ç”¨å…³é—­æ—¶è°ƒç”¨ï¼‰"""
    async with _client_lock:
        for url, client in _shared_clients.items():
            if not client.is_closed:
                await client.aclose()
                logger.info(f"å…³é—­å…±äº« HTTP å®¢æˆ·ç«¯: {url}")
        _shared_clients.clear()


# ==================== å…±äº« Agent æ±  ====================

_shared_agents: Dict[str, "DualLLMAgent"] = {}
_agent_lock = asyncio.Lock()


async def get_shared_agent(config: LLMConfig) -> "DualLLMAgent":
    """
    è·å–å…±äº«çš„ DualLLMAgentï¼ˆé¿å…æ¯æ¬¡è¯·æ±‚éƒ½åˆ›å»ºæ–° Agentï¼‰
    
    ä½¿ç”¨ base_url ä½œä¸º keyï¼Œå› ä¸ºé€šå¸¸åŒä¸€ä¸ª API ç«¯ç‚¹ä½¿ç”¨åŒä¸€ä¸ªå®¢æˆ·ç«¯
    """
    key = config.base_url
    
    async with _agent_lock:
        if key not in _shared_agents:
            agent = DualLLMAgent(config, use_shared_client=True)
            _shared_agents[key] = agent
            logger.info(f"åˆ›å»ºå…±äº« Agent: {key}")
        else:
            # æ›´æ–°é…ç½®ï¼ˆAPI key å¯èƒ½å˜åŒ–ï¼‰
            _shared_agents[key].config = config
        return _shared_agents[key]


# ==================== ä¾¿æ·å‡½æ•° ====================

async def create_dual_llm_agent(
    base_url: str,
    api_key: str,
    model: str,
    intent_model: Optional[str] = None,
    summary_model: Optional[str] = None,
) -> DualLLMAgent:
    """åˆ›å»ºåŒ LLM Agent"""
    config = LLMConfig(
        base_url=base_url,
        api_key=api_key,
        model=model,
        intent_model=intent_model,
        summary_model=summary_model,
    )
    return DualLLMAgent(config)


async def quick_process(
    user_input: str,
    base_url: str,
    api_key: str,
    model: str,
) -> DualLLMResult:
    """å¿«é€Ÿå¤„ç†å•ä¸ªè¾“å…¥"""
    agent = await create_dual_llm_agent(base_url, api_key, model)
    try:
        return await agent.process(user_input)
    finally:
        await agent.close()
