"""
å·¥å…·æ‰§è¡Œå™¨

è´Ÿè´£è§£æå’Œæ‰§è¡Œ LLM çš„å·¥å…·è°ƒç”¨è¯·æ±‚ã€‚
"""

from typing import Any, Dict, List, Optional, Union
from .base import BaseTool, ToolResult
from .registry import tool_registry
import json
import logging

logger = logging.getLogger(__name__)


class ToolExecutor:
    """
    å·¥å…·æ‰§è¡Œå™¨
    
    è´Ÿè´£æ‰§è¡Œå·¥å…·è°ƒç”¨ï¼Œæ”¯æŒï¼š
    - å•ä¸ªå·¥å…·è°ƒç”¨
    - æ‰¹é‡å·¥å…·è°ƒç”¨
    - ä» LLM å“åº”ä¸­è§£æå¹¶æ‰§è¡Œå·¥å…·è°ƒç”¨
    
    ä½¿ç”¨ç¤ºä¾‹:
        # ç›´æ¥æ‰§è¡Œ
        result = await executor.execute("base64_encode", {"text": "hello"})
        
        # ä» LLM å“åº”æ‰§è¡Œ
        results = await executor.execute_from_llm_response(llm_response)
    """
    
    def __init__(self, registry: Optional["ToolRegistry"] = None):
        self._registry = registry or tool_registry
    
    async def execute(
        self,
        tool_name: str,
        arguments: Dict[str, Any],
        require_confirmation: bool = True,
    ) -> ToolResult:
        """
        æ‰§è¡Œå•ä¸ªå·¥å…·
        
        Args:
            tool_name: å·¥å…·åç§°
            arguments: å·¥å…·å‚æ•°
            require_confirmation: æ˜¯å¦æ£€æŸ¥ç¡®è®¤è¦æ±‚
            
        Returns:
            ToolResult: æ‰§è¡Œç»“æœ
        """
        tool = self._registry.get(tool_name)
        
        if not tool:
            return ToolResult.fail(f"å·¥å…·ä¸å­˜åœ¨: {tool_name}")
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦ç¡®è®¤
        if require_confirmation and tool.requires_confirmation:
            logger.warning(f"ğŸ”§ [ToolExecutor] å·¥å…·éœ€è¦ç¡®è®¤: {tool_name}")
            return ToolResult(
                success=False,
                error="æ­¤å·¥å…·éœ€è¦ç”¨æˆ·ç¡®è®¤åæ‰èƒ½æ‰§è¡Œ",
                data={"requires_confirmation": True, "tool_name": tool_name}
            )
        
        import time
        start_time = time.time()
        logger.info(f"ğŸ”§ [ToolExecutor] å¼€å§‹æ‰§è¡Œ: {tool_name}({arguments})")
        
        try:
            result = await tool.execute(**arguments)
            elapsed = (time.time() - start_time) * 1000
            logger.info(f"ğŸ”§ [ToolExecutor] æ‰§è¡Œå®Œæˆ: {tool_name}, success={result.success}, è€—æ—¶={elapsed:.0f}ms")
            return result
        except Exception as e:
            elapsed = (time.time() - start_time) * 1000
            logger.error(f"ğŸ”§ [ToolExecutor] æ‰§è¡Œå¼‚å¸¸: {tool_name}, error={e}, è€—æ—¶={elapsed:.0f}ms", exc_info=True)
            return ToolResult.fail(f"æ‰§è¡Œå¼‚å¸¸: {str(e)}")
    
    async def execute_batch(
        self,
        calls: List[Dict[str, Any]],
        stop_on_error: bool = False,
    ) -> List[Dict[str, Any]]:
        """
        æ‰¹é‡æ‰§è¡Œå·¥å…·
        
        Args:
            calls: å·¥å…·è°ƒç”¨åˆ—è¡¨ï¼Œæ¯é¡¹åŒ…å« {tool_name, arguments, call_id?}
            stop_on_error: é‡åˆ°é”™è¯¯æ˜¯å¦åœæ­¢
            
        Returns:
            æ‰§è¡Œç»“æœåˆ—è¡¨
        """
        results = []
        
        for call in calls:
            tool_name = call.get("tool_name") or call.get("name")
            arguments = call.get("arguments", {})
            call_id = call.get("call_id") or call.get("id")
            
            result = await self.execute(tool_name, arguments)
            
            results.append({
                "call_id": call_id,
                "tool_name": tool_name,
                "result": result.model_dump(),
            })
            
            if stop_on_error and not result.success:
                break
        
        return results
    
    def parse_tool_calls(self, llm_response: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        ä» LLM å“åº”ä¸­è§£æå·¥å…·è°ƒç”¨
        
        æ”¯æŒ OpenAI æ ¼å¼çš„å“åº”ã€‚
        
        Args:
            llm_response: LLM API çš„å“åº”
            
        Returns:
            å·¥å…·è°ƒç”¨åˆ—è¡¨
        """
        tool_calls = []
        
        # OpenAI æ ¼å¼
        choices = llm_response.get("choices", [])
        if choices:
            message = choices[0].get("message", {})
            calls = message.get("tool_calls", [])
            
            for call in calls:
                if call.get("type") == "function":
                    function = call.get("function", {})
                    tool_calls.append({
                        "call_id": call.get("id"),
                        "tool_name": function.get("name"),
                        "arguments": self._parse_arguments(function.get("arguments", "{}")),
                    })
        
        return tool_calls
    
    def _parse_arguments(self, arguments: Union[str, dict]) -> Dict[str, Any]:
        """è§£æå‚æ•°ï¼ˆå¯èƒ½æ˜¯ JSON å­—ç¬¦ä¸²æˆ–å­—å…¸ï¼‰"""
        if isinstance(arguments, dict):
            return arguments
        try:
            return json.loads(arguments)
        except json.JSONDecodeError:
            return {}
    
    async def execute_from_llm_response(
        self,
        llm_response: Dict[str, Any],
        stop_on_error: bool = False,
    ) -> List[Dict[str, Any]]:
        """
        ä» LLM å“åº”ä¸­è§£æå¹¶æ‰§è¡Œå·¥å…·è°ƒç”¨
        
        Args:
            llm_response: LLM API çš„å“åº”
            stop_on_error: é‡åˆ°é”™è¯¯æ˜¯å¦åœæ­¢
            
        Returns:
            æ‰§è¡Œç»“æœåˆ—è¡¨
        """
        tool_calls = self.parse_tool_calls(llm_response)
        
        if not tool_calls:
            return []
        
        return await self.execute_batch(tool_calls, stop_on_error)
    
    def format_tool_results_for_llm(
        self,
        results: List[Dict[str, Any]],
    ) -> List[Dict[str, Any]]:
        """
        å°†å·¥å…·æ‰§è¡Œç»“æœæ ¼å¼åŒ–ä¸º LLM å¯ç†è§£çš„æ¶ˆæ¯æ ¼å¼
        
        Args:
            results: execute_batch è¿”å›çš„ç»“æœ
            
        Returns:
            å¯æ·»åŠ åˆ° messages çš„å·¥å…·ç»“æœæ¶ˆæ¯åˆ—è¡¨
        """
        messages = []
        
        for r in results:
            call_id = r.get("call_id")
            result = r.get("result", {})
            
            # æ ¼å¼åŒ–è¾“å‡ºå†…å®¹
            if result.get("success"):
                content = json.dumps(result.get("data"), ensure_ascii=False, indent=2)
            else:
                content = f"é”™è¯¯: {result.get('error', 'æœªçŸ¥é”™è¯¯')}"
            
            messages.append({
                "role": "tool",
                "tool_call_id": call_id,
                "content": content,
            })
        
        return messages


# å…¨å±€å·¥å…·æ‰§è¡Œå™¨å®ä¾‹
tool_executor = ToolExecutor()

